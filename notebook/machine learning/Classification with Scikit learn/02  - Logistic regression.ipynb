{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the diabetes data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as sklm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cancer[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = cancer[\"data\"]\n",
    "labels = cancer[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame(data=features,columns=cancer[\"feature_names\"])\n",
    "labels_df = pd.DataFrame(data=labels,columns=[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split the data into training and test set with 80 - 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(features_df,labels_df,test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit the logistic regression on training data to create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### see the coefficients and intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature,coef in zip(cancer[\"feature_names\"],lr.coef_.flatten()):\n",
    "    print(feature,coef)\n",
    "print(\"intercept {}\".format(lr.intercept_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict the classes on the new data set i.e our test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model outputs probabilities for each class. The class with the highest probability is taken as the score (prediction). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = lr.predict_proba(X_test)\n",
    "print(probabilities[:15,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column is the probability of a score of $0$ and the second column is the probability of a score of $1$. Notice that for most, but not all cases, the probability of a score of $0$ is higher than $1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score and evaluate the classification model\n",
    "\n",
    "Now that the class probabilities have been computed these values must be transformed into actual class scores. Recall that the log likelihoods for two-class logistic regression are computed by applying the sigmoid or logistic transformation to the output of the linear model. The simple choice is to set the threshold between the two likelihoods at $0.5$. The code in the cell below applies this initial threshold to the probability of a score of $0$ for the test data. A few examples along with the known labels are then displayed. Execute this code and examine the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1 1 1 0 0 0 1 1 0 1 0]\n",
      "[0 1 1 0 1 1 1 1 0 0 1 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "scores = score_model(probabilities, 0.5)\n",
    "print(np.array(scores[:15]))\n",
    "print(np.array(y_test[:15]).flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the positive ($1$) predictions agree with the test labels in the second row, but several do not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation metrics\n",
    "\n",
    "For classifiers there are a number of metrics commonly used. The **confusion matrix** lays out the correctly and incorrectly classified cases in a tabular format. There are various metrics derived from the values in the confusion matrix. Some of the common cases are briefly reviewed below. \n",
    "\n",
    "**Confusion matrix**\n",
    "\n",
    "The confusion matrix lays out correctly and incorrectly classified cases. For the binary (two-class) case the confusion matrix is organized as follows:\n",
    "\n",
    "| | Scored Positive | Scored Negative|  \n",
    "|------|:------:|:------:| \n",
    "|**Actual Positive** | True Positive | False Negative |\n",
    "|**Actual Negative**| False Positive | True Negative |   \n",
    "\n",
    "Here the four elements in the matrix are defined as:    \n",
    "**True Positive** or **TP** are cases with positive labels which have been correctly classified as positive.     \n",
    "**True Negative** or **TN** are cases with negative labels which have been correctly classified as negative.  \n",
    "**False Positive** or **FP** are cases with negative labels which have been incorrectly classified as positive.   \n",
    "**False Negative** or **FN** are cases with positive labels which have been incorrectly classified as negative.\n",
    "\n",
    "When creating a confusion matrix it is important to understand and maintain a convention for which differentiating positive and negative label values. The usual convention is to call the $1$ case positive and the $0$ case negative. \n",
    "\n",
    "Notice that there is an ambiguity in which case is considered positive and which is considered negative when the confusion matrix is computed. Whenever you examine a confusion matrix it is a good idea to spend a moment and decide which case is which. This step will help you relate the results to the problem at hand. \n",
    "\n",
    "**Accuracy**\n",
    "\n",
    "Accuracy is a simple and often misused metric. In simple terms, accuracy is the fraction of cases correctly classified. For a two-class classifier accuracy is written as:\n",
    "\n",
    "$$Accuracy = \\frac{TP+TN}{TP+FP+TN+FN}$$\n",
    "\n",
    "Accuracy can be quite misleading. For example, say a classifier is used to detect fraudulent accounts and the rate of fraud is less than 1%. A naive model would be to say all accounts are not fraudulent. This model has accuracy exceeding  0.99. This sounds impressive, but is clearly useless. \n",
    "\n",
    "**Precision**\n",
    "\n",
    "Precision is the fraction of correctly classified label cases out of all cases classified with that label value. We can express precision by the following relationship:\n",
    "\n",
    "$$Precision = \\frac{M_{i,i}}{\\sum_j M_{i,j}}$$\n",
    "\n",
    "$$ \\text{precision} = \\frac{TP}{FP + TP} $$\n",
    "\n",
    "In other words, the precision statistic is the number of correctly classified cases for the label value divided by all the cases in the column. Thus, precision is sensitive to the number of cases correctly classified for a given score value. \n",
    "\n",
    "**Recall**  \n",
    "\n",
    "Recall is the fraction of cases of a label value correctly classified out of all cases that actually have that label value. We can express recall by the following relationship:\n",
    "\n",
    "$$Recall = \\frac{M_{i,i}}{\\sum_i M_{i,j}}$$\n",
    "\n",
    "$$ \\text{recall} = \\frac{TP}{FN + TP} $$\n",
    "\n",
    "\n",
    "In other words, the recall statistic is the number of correctly classified cases for the label value divided by all the cases in the row. Thus, precision is sensitive to the number of cases correctly classified for a given true label value. \n",
    "\n",
    "**F1**\n",
    "\n",
    "The F1 statistic is weighted average of precision and recall. We can express F1 by the following relationship:\n",
    "\n",
    "$$F1 = 2 * \\frac{precision * recall}{precision + recall}$$\n",
    "\n",
    "In other words, F1 is a weighted metric for overall model performance. \n",
    "\n",
    "**ROC** and **AUC**\n",
    "\n",
    "The receiver operating characteristic or ROC is a curve that displays the relationship between the true positive rate on the vertical axis and false positive rate on the horizontal axis. The ROC curve shows the tradeoff between true positive rate and false positive rate. An example is illustrated below.   \n",
    "\n",
    "In principle, you can pick the desired operating point for a classifier on this curve. Towards the left favors low false positive rate at the expense of true positive rate. Towards the right favors high true positive rate at the expense of higher false positive rate.  \n",
    "\n",
    "\n",
    "\n",
    "<img src=\"img/ROC_AUC.JPG\" alt=\"drawing\" width=\"480px\"/>\n",
    "\n",
    "\n",
    "<center>**ROC curve with values of AUC for balanced two-class problem**</center>\n",
    "\n",
    "The AUC is the area or integral under the ROC curve. The overall performance of the classifier is measured by the area under the curve or AUC. But, how can you interpret a specific AUC value? The higher the AUC the lower the increase in false positive rate required to achieve a required true positive rate.  For an ideal classifier the AUC is 1.0. A true positive rate is achieved with a 0 false positive rate. This behavior means that AUC is useful for comparing classifiers. The classifier with higher AUC is generally the better one.\n",
    "\n",
    "For balanced cases, random guessing gives an AUC or 0.5. A balanced case has equal numbers of positive and negative cases. So Bernoulli sampling (random guessing) with a probability $p$ for the positive case, will produce a ROC curve that runs diagonally from $0.0,0.0$ to $1.0,1.0$. The area under this triangular region is 0.5. It is often said that a classifier with an AUC of greater than 0.5 is better than random guessing. But, **for unbalanced cases this statement is not in true in general**. \n",
    "\n",
    "****\n",
    "**Note:** The term receive operating characteristic may seem a bit odd in the machine learning context. This term arose in the early days of radar engineering as a metric to measure the tradeoff between radar signal receiver correctly detecting a target, say an aircraft, and producing a positive response from noise, such as flying birds or clouds. A radar receiver would be adjusted to the desired operating point along its ROC curve. \n",
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive        37                 2\n",
      "Actual negative         5                70\n",
      "\n",
      "Accuracy  0.94\n",
      " \n",
      "           Positive      Negative\n",
      "Num case       39            75\n",
      "Precision    0.88          0.97\n",
      "Recall       0.95          0.93\n",
      "F1           0.91          0.95\n"
     ]
    }
   ],
   "source": [
    "def print_metrics(labels, scores):\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy  %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "\n",
    "\n",
    "    \n",
    "print_metrics(y_test, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_auc(labels, probs):\n",
    "    ## Compute the false positive rate, true positive rate\n",
    "    ## and threshold along with the AUC\n",
    "    fpr, tpr, threshold = sklm.roc_curve(labels, probs[:,1])\n",
    "    auc = sklm.auc(fpr, tpr)\n",
    "    \n",
    "    ## Plot the result\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, color = 'orange', label = 'AUC = %0.2f' % auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    \n",
    "plot_auc(y_test, probabilities)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
